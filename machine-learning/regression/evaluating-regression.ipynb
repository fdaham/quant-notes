{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Regression\n",
    "\n",
    "## Error Metrics\n",
    "\n",
    "Error metrics, or residuals, are used in linear regression models to evaluate model performance. These metrics measure the difference between actual and predicted values. \n",
    "\n",
    "### Mean Absolute Error\n",
    "\n",
    "Mean Absolute Error (MAE) is the average absolute difference between actual and predicted model values. MAE handles outliers well because of the absolute value and large errors don't overpower the smaller ones, so its output gives an unbiased view of the model's performance. \n",
    "\n",
    "\\begin{equation*}      \n",
    "\\text{MAE} = \\sum_{i=1}^{n} \\frac{|y_i - x_i|}{n}\n",
    "\\label{eq:1} \\tag{1}\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_actual = [3, -0.5, 1, 3.5]\n",
    "y_pred = [2.5, 0, 0.2, 3]\n",
    "mean_absolute_error(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "\n",
    "Mean Squared Error (MSE) is the average squared difference between actual and predicted model values. Unlike MAE, MSE heavily counts against outliers. The square allows larger errors to overpower the smaller ones, which means a single outlier could yield a high error value--allowing us to assume that the model is worse than it actually is. On the other hand, if all the errors are small (i.e. less than 1), we may assume the model is better than it actually is.  \n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2 \n",
    "\\label{eq:2} \\tag{2}\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34750000000000003"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error\n",
    "\n",
    "Root Mean Squared Error (RMSE) is the average root-squared difference between actual and predicted model values. It's the root-squared value of MSE.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2} \n",
    "\\label{eq:3} \\tag{3}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5894913061275798"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_actual, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Squared\n",
    "\n",
    "The $R^2$ score, or the coefficient of determination, measures the proportion of variance of the dependent variable explained by the independent variable. The closer $R^2$ is to 1, the better. $R^2$ also the square of the correlation between the independent variables. Below is the equation for $R^2$, where $\\text{SSE}$ is the sum of squared errors and $\\text{SST}$ is the total sum of squares.\n",
    "\n",
    "\\begin{equation*}   \n",
    "\\text{R}^2 = 1 - \\frac{\\sum_{i=1}^m (y_i - \\hat{y_i})^2}{\\sum_{i=1}^m (y_i - \\bar{y})^2} = 1 - \\frac{\\text{SSE}}{\\text{SST}}\n",
    "\\label{eq:4} \\tag{4}\n",
    "\\end{equation*} \n",
    "\n",
    "The **Adjusted $R^2$** score is a modified version of $R^2$ that accounts for the number of predictors in the model. It increases if a new term improves the fit and decreases if there's little to no improvement. Below is the equation for $\\text{R}_{\\text{adj}}^2$, where $n$ is the total sample size and $k$ is the number of predictors.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{R}_{\\text{adj}}^2 =  1 - \\frac{\\text{SSE}}{\\text{SST}} \\cdot \\frac{n-1}{n-k-1} \n",
    "\\label{eq:5} \\tag{5}\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_actual, y_pred)\n",
    "n, k = len(y_actual), x_pred.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "*Running an OLS regression of $y$ ~ $x_1$ gives $R_1^2 = 0.3$. Running an OLS regression of $y$ ~ $x_2$ gives $R_2^2 = 0.4$. Find $R^2$ for $y$ ~ $x_1 + x_2$.* \n",
    "\n",
    "$R_1^2 \\neq R_2^2$, which means $x_1$ and $x_2$ aren't perfectly correlated. We don't know anything else about $x_1$ and $x_2$, so we'll need to express $R^2$ as a range of values. The maximum bound for $R^2$ is reached when $x_1$ and $x_2$ are orthogonal, or uncorrelated. In this case, $R^2 = \\text{min}(R_1^2 + R_2^2, 1) = 0.7$. The minimum bound for $R^2$ is reached when $x_2$ contains all the information of $x_1$. In this case, $R^2 = R_2^2 = 0.4$. Therefore, $0.4 \\leq R^2 \\leq 0.7$. \n",
    "\n",
    "The result is simulated below using the following equation for $R^2$ with only correlation coefficients:\n",
    "\n",
    "\\begin{equation*}   \n",
    "\\text{R}^2 = \\frac{r_{y,x_1}^2 + r_{y,x_2}^2 - 2 r_{y,x_1}r_{y,x_2}r_{x_1,x_2}}{1 - r_{x_1,x_2}^2}\n",
    "\\label{eq:6} \\tag{6}\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(range(100))/100\n",
    "y = (0.3 + 0.4 - 2*(0.3**0.5)*(0.4**0.5)*x)/(1-x**2)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xlabel('$r_{x_1,x_2}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "\n",
    "### Coefficients\n",
    "\n",
    "Coefficients describe the relationship between each independent variable and the dependent variable. The first coefficient without an input is called the **intercept**. Think of it as the base case of your model. The intercept adjusts what the model predicts when all your inputs are 0. \n",
    "\n",
    "The remaining coefficients are the **regression coefficients**. They give the slope of the line of best fit. The sign of a regression coefficient tells you whether there is a positive or negative correlation between each independent variable and the dependent variable. A positive coefficient indicates that the mean of the dependent variable will increase as the value of the independent variable increases. A negative coefficient indicates that the dependent variable will decrease as the independent variable increases.\n",
    "\n",
    "For a simple linear regression, the regression coefficient can be written in terms of the correlation coefficient and standard deviations of $x$ and $y$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\beta = r_{xy} \\frac{\\sigma_y}{\\sigma_x}\n",
    "\\label{eq:7} \\tag{7}\n",
    "\\end{equation*}  \n",
    "\n",
    "A regression with two independent variables, the regression coefficients $\\beta_1$ and $\\beta_2$ are calculated as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\beta_1 &= \\frac{\\sum x_2^2 \\sum x_1 y - \\sum x_1 x_2 \\sum x_2 y}{\\sum x_1^2 \\sum x_2^2 - \\sum x_1 x_2} \\\\\n",
    "\\beta_2 &= \\frac{\\sum x_1^2 \\sum x_2 y - \\sum x_1 x_2 \\sum x_1 y}{\\sum x_1^2 \\sum x_2^2 - \\sum x_1 x_2}\n",
    "\\end{split}\n",
    "\\label{eq:8} \\tag{8}\n",
    "\\end{equation*}   \n",
    "\n",
    "We can also find $R^2$ using these regression coefficients:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{R}^2 = \\beta_1 r_{y,x1} + \\beta_2 r_{y,x2}\n",
    "\\label{eq:9} \\tag{9}\n",
    "\\end{equation*}  \n",
    "\n",
    "### Statistical Testing\n",
    "\n",
    "See [here](http://mathcenter.oxford.emory.edu/site/math117/hypothesisTestsProportionsOneSample/) for an in-depth explanation (with an example) of hypothesis testing, standard errors, t-statistics, p-values, and the empirical rule. To summarize, let's say we have the following null and alternate hypothesis:\n",
    "\n",
    "\\begin{equation*}   \n",
    "\\text{H}_0: p = 0.5, \\text{H}_1: p \\neq 0.5 \n",
    "\\end{equation*} \n",
    "\n",
    "The following can be used to find the **standard error**:\n",
    "\n",
    "\\begin{equation*}   \n",
    "\\text{SE} = \\sqrt{\\frac{\\sigma}{n}} = \\sqrt{\\frac{p(1-p)}{n}}\n",
    "\\label{eq:10} \\tag{10}\n",
    "\\end{equation*} \n",
    "\n",
    "where $\\sigma$ is the sample standard deviation and $n$ is the sample size. From here, we can calculate the **t-statistic**, or the z-score of the sample distribution:\n",
    "\n",
    "\\begin{equation*}   \n",
    "t = \\frac{x - \\mu}{\\text{SE}}\n",
    "\\label{eq:11} \\tag{11}\n",
    "\\end{equation*} \n",
    "\n",
    "where $x$ is the observed $p$ and $\\mu = p$ for a normal distribution. You can use this $t$ to find the p-value, or the probability that $X$ falls after $t$. If the p-value is less than the significance level, $\\alpha$, we reject the null hypothesis. You can also calculate $t$ in terms of the correlation coefficient:\n",
    "\n",
    "\\begin{equation*}   \n",
    "t = r \\cdot \\frac{n-2}{1-r^2}\n",
    "\\label{eq:12} \\tag{12}\n",
    "\\end{equation*} \n",
    "\n",
    "Instead of p-values, the **empirical rule** can be used to assess the null hypothesis. The rule states that 68.3% of the probability distribution falls within one standard deviation of the mean, 95.5% within two, and 99.7% within three. For example, if $t = 2.2$ and $\\alpha = 0.05$, I can discount at least 95.5% of my probability distribution--leaving only 4.5%. 0.045 is less than $\\alpha$, so I'd reject my null hypothesis. \n",
    "\n",
    "### Effects of Input Changes\n",
    "\n",
    "The table below summarizes which of the above regression variables change once the input data changes for some predicted output $\\hat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_n X_n + \\epsilon$.\n",
    "\n",
    "Type of Change | Effect on Coefficients | Effect on T-Statistic | Effect on $R^2$\n",
    "--------------------------------------------|-----------------------------|---------------------------|---------------------------\n",
    "Swapping $X$ and $Y$ in a simple linear model |The slope of the regression line will be a rescaled version of the old one; $r_{xy} = r_{yx}$ since the correlation coefficient is symmetrical, so $\\beta_{yx} = r_{xy} \\frac{\\sigma_y}{\\sigma_x}$  and $\\beta_{xy} = r_{yx} \\frac{\\sigma_x}{\\sigma_y} = \\beta_{yx} \\frac{\\sigma_x^2}{\\sigma_y^2}$| None; the correlation coefficients are symmetrical | None; $R^2 = r_{xy}^2 = r_{yx}^2$\n",
    "Duplicating the covariates | None; Generally, mean and variance of the sample remain the same. Mathematically, $\\beta$ remains unchanged ([proof](https://stats.stackexchange.com/questions/216003/what-are-the-consequences-of-copying-a-data-set-for-ols)). | Increases; t-statistic is directly proportional to the sample size | None; regression coefficients and correlation coefficients remain the same\n",
    "Changing the sample size, $n$ | Coefficients aren't directly affected by the sample size, but they are affected by the sampling variation. Sampling variability decreases as the sample size increases. | Increases or decreases | Affected by the sampling variation\n",
    "Adding a new covariate, $X_i$ | All coefficients are jointly estimated, so a new variable will change the existing coefficients | Affected by the change in the joint variance of $Y$ | Increases; any new nonzero term will improve the fit and increase $R^2$\n",
    "Removing a covariate, $X_i$ |All coefficients are jointly estimated, so removing a variable will change the remaining coefficients| Affected by the change in the joint variance of $Y$ | Affected by the change in the regression coefficient and variance\n",
    "Changing units for a covariate, $X_i$ | Changes the unit of the corresponding coefficient, $\\beta_i$ | None | None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
