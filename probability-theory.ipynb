{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Theory\n",
    "\n",
    "## Combinatorics\n",
    "\n",
    "### Permutations\n",
    "\n",
    "Permutations are rearrangements of objects in unqiue sequences. The total number of permutations of $n$ objects where $n_1, n_2, \\cdots, n_k$ are alike is calculated as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{n!}{n_1!n_2! \\cdots n_k!} = \\frac{n!}{(n-k)!}\n",
    "\\label{eq:1} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "If we're just looking to order $n$ different objects, then the total number of permutations would just be $n!$.\n",
    "\n",
    "### Combinations\n",
    "\n",
    "Unlike permutations, combinations are an unordered collection of objects. For $n$ distinct objects taken $k$ at a time without repetition, we can calculate the total number of combinations using the Binomial Coefficient:\n",
    "\n",
    "\\begin{equation*}\n",
    "{n \\choose k} = \\frac{n!}{k!(n-k)!}\n",
    "\\label{eq:2} \\tag{2}\n",
    "\\end{equation*}\n",
    "\n",
    "Symmetry rule of the Binomial Coefficient:\n",
    "\n",
    "\\begin{equation*}\n",
    "{n \\choose k} = {n \\choose {n-k}}\n",
    "\\label{eq:3} \\tag{3}\n",
    "\\end{equation*}\n",
    "\n",
    "Here's the short proof of that. Let $0 \\leq k \\leq n$. Then:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "{n \\choose k} &= \\frac{n!}{k!(n-k)!} = \\frac{n!}{(n-k)!k!} \\\\\n",
    "&= \\frac{n!}{(n-k)!(n-(n-k))!} = {n \\choose n-k}\n",
    "\\end{split}\n",
    "\\label{eq:4} \\tag{4}\n",
    "\\end{equation*}\n",
    "\n",
    "### Binomial Theorem\n",
    "\n",
    "The Binomial Theorem is the expansion of powers of a binomial. \n",
    "\n",
    "\\begin{equation*}\n",
    "(x+y)^n = \\sum_{k=0}^{n} {n \\choose k} x^k y^{n-k}\n",
    "\\label{eq:5} \\tag{5}\n",
    "\\end{equation*}\n",
    "\n",
    "### Inclusion-Exclusion Principle\n",
    "\n",
    "\\begin{equation*}\n",
    "P(E_1 \\cup E_2) = P(E_1) + P(E_2) - P(E_1 E_2)\n",
    "\\label{eq:6} \\tag{6}\n",
    "\\end{equation*}\n",
    "\n",
    "More generally,\n",
    "\n",
    "\\begin{equation*}\n",
    "P(E_1 \\cup \\cdots \\cup E_n) = \\sum_{i=1}^{n} P(E_i) - \\sum_{i_1<i_2} P(E_{i_1} E_{i_2}) + \\cdots + (-1)^{r+1} \\sum_{i_1<i_2< \\cdots <i_r} P(E_{i_1} E_{i_2} \\cdots E_{i_r}) + \\cdots + (-1)^{n+1} P(E_1 E_2 \\cdots E_n)\n",
    "\\label{eq:7} \\tag{7}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "Conditional probability is the probability that an event will occur given that another event has already occurred. It's calculated using Bayes' Theorem:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(E|F) = \\frac{P(E F)}{P(F)}, P(F) \\neq 0\n",
    "\\label{eq:8} \\tag{8}\n",
    "\\end{equation*}\n",
    "\n",
    "Here's the short proof of that:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "P(E \\cap F) &= P(F \\cap E) \\\\\n",
    "\\Rightarrow P(F|E)P(E) &= P(E|F)P(F) \\\\\n",
    "\\Rightarrow P(E|F) &= \\frac{P(F|E)P(E)}{P(F)} = \\frac{P(E F)}{P(F)}\n",
    "\\end{split}\n",
    "\\label{eq:9} \\tag{9}\n",
    "\\end{equation*}\n",
    "\n",
    "### Multiple Events\n",
    "\n",
    "If there were some other event $E^C$ partitioning the sample space, then Bayes' theorem becomes:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(E|F) = \\frac{P(F|E)P(E)}{P(F|E)P(E) + P(F|E^C)P(E^C)}\n",
    "\\label{eq:10} \\tag{10}\n",
    "\\end{equation*}\n",
    "\n",
    "In general, for multiple events $E_j$ partitioning the sample space:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(E_i|F) = \\frac{P(F|E_i)P(E_i)}{\\sum_{j=1}^{N} P(F|E_j)P(E_j)}\n",
    "\\label{eq:11} \\tag{11}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Example\n",
    "\n",
    "I have two fair coins and one double headed coin. I pick one coin at random. What's the chance of having picked a double headed coin if 100 consecutive coin tosses yield 100 heads?\n",
    "\n",
    "Let $E$ be the event that the coin is fair, $E^C$ be the event that the coin isn't fair, and $F$ be the event that 100 coin tosses yield 100 heads. Then,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "P(E|F) &= \\frac{P(F|E)P(E)}{P(F|E)P(E) + P(F|E^C)P(E^C)}\n",
    "&= \\frac{\\left( 1\\right) \\left( \\frac{1}{3}\\right)}{\\left(1\\right) \\left( \\frac{1}{3}\\right) + \\left( {\\frac{1}{2}}^{100} \\right) \\left(\\frac{2}{3} \\right)} \\approx 1 \n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "### Product Rule\n",
    "\n",
    "As used in the proof above:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(EF) = P(F|E)P(E)\n",
    "\\label{eq:12} \\tag{12}\n",
    "\\end{equation*}\n",
    "\n",
    "More generally,\n",
    "\n",
    "\\begin{equation*}\n",
    "P(E_1 E_2 \\cdots E_3) = P(E_1)P(E_2|E_1)P(E_3|E_1 E_2) \\cdots P(E_n|E_1 \\cdots E_{n-1})\n",
    "\\label{eq:13} \\tag{13}\n",
    "\\end{equation*}\n",
    "\n",
    "### Law of Total Probability\n",
    "\n",
    "For any mutually exclusive events {$F_i$}, where $1 \\leq i \\leq n$, the probability of event $E$ occurring is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "P(E) &= P(EF_1) + P(EF_2) + \\cdots + P(EF_n) \\\\\n",
    "&= P(E|F_1)P(F_1) + P(E|F_2)P(F_2) + \\cdots + P(E|F_n)P(F_n) \n",
    "= \\sum_{i=1}^{n} P(E|F_i)P(F_i) \n",
    "\\end{split}\n",
    "\\label{eq:14} \\tag{14}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Variables\n",
    "\n",
    "### Expected Value\n",
    "\n",
    "The expected value of a random variable, $E[X]$, is the weighted average of its possible outcomes. If random variable $X$ is **discrete** with probability $P(X = x)$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "E [X] = \\sum x P(x)\n",
    "\\label{eq:15} \\tag{15}\n",
    "\\end{equation*}\n",
    "\n",
    "If $X$ is **continuous** with a PDF of $f(x)$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "E [X] = \\int_{-\\infty}^{\\infty} xf(x)dx\n",
    "\\label{eq:16} \\tag{16}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Linearity of expectation\n",
    "\n",
    "Linearity of expectation states that the sum of the expected values of random variables is the sum of their individual expected values--regardless of whether they are independent or not. For random variables $X$ and $Y$, this means:\n",
    "\n",
    "\\begin{equation*}\n",
    "E [X+Y] = E[X] + E[Y]\n",
    "\\label{eq:17} \\tag{17}\n",
    "\\end{equation*}\n",
    "\n",
    "More generally,\n",
    "\n",
    "\\begin{equation*}\n",
    "E \\left[ \\sum_{i=1}^{n} X_i \\right] = \\sum_{i=1}^{n} E[X_i]\n",
    "\\label{eq:18} \\tag{18}\n",
    "\\end{equation*}\n",
    "\n",
    "##### Example\n",
    "\n",
    "You throw a fair coin one million times. What is the expected number of occurences of HHHHHHTTTTTT?\n",
    "\n",
    "The probability $p_i$ of getting HHHHHHTTTTTT is $\\frac{1}{2^{12}}$. For one million tosses, there are $n = 1000000 - 11$ possible chances for this sequence to occur. Let $X_i$ have a value of $1$ if the sequence starting at $i$ is equal to HHHHHHTTTTTT. Then, using the linearity of expectation, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "E \\left[ \\sum_{i=1}^{n} X_i \\right] = \\sum_{i=1}^{n} E[X_i] = n p_i = \\frac{1000000-11}{2^{12}}\n",
    "\\end{equation*}\n",
    "\n",
    "### Variance and Covariance\n",
    "\n",
    "The variance of a random variable $X$ is:\n",
    "\n",
    "\\begin{equation*}\n",
    "V(X) = \\sigma_X^2\n",
    "\\label{eq:19} \\tag{19}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\sigma_X$ is the standard deviation of $X$. In terms of the expected value, it can be rewritten as:\n",
    "\n",
    "\\begin{equation*}\n",
    "V(X) = E[(X - E[X])^2] = E[X^2] - E[X]^2\n",
    "\\label{eq:20} \\tag{20}\n",
    "\\end{equation*}\n",
    "\n",
    "The covariance of random variables $X$ and $Y$ is:\n",
    "\n",
    "\\begin{equation*}\n",
    "C(X, Y) = E[XY] - E[X]E[Y]\n",
    "\\label{eq:21} \\tag{21}\n",
    "\\end{equation*}\n",
    "\n",
    "And the correlation of $X$ and $Y$ is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\rho(X, Y) = \\frac{Cov(X, Y)}{Var(X)Var(Y)}\n",
    "\\label{eq:22} \\tag{22}\n",
    "\\end{equation*}\n",
    "\n",
    "If X and Y are independent, then $Cov(X, Y) = 0$ and $\\rho(X, Y) = 0$. \n",
    "\n",
    "#### Covariance Matrices\n",
    "\n",
    "Covariance matrices show the covariance between variables. They are symmetrical and positive semidefinite--meaning all values in the matrix are greater than or equal to zero. The determinant test is used to determine whether a matrix is a covariance matrix by computing the determinants of the growing submatrices in the upper left corner of the matrix. If they are all positive semidefinite, then the matrix is a covariance matrix.\n",
    "\n",
    "##### Example\n",
    "\n",
    "For three assets $A$, $B$, and $C$, the correlation coefficient of $A$ and $B$ is 0.9 and is 0.8 for $B$ and $C$. With that in mind, can $A$ and $C$ have a correlation coefficient of 0.1?\n",
    "\n",
    "\\begin{equation*}\n",
    "ABC = \\begin{bmatrix}V_{A,A}&C_{A,B}&C_{A,C}\\\\C_{B,A}&V_{B,B}&C_{B,C}\\\\C_{C,A}&C_{C,B}&V_{C,C}\\end{bmatrix} = \\begin{bmatrix}1 & 0.9 & 0.1\\\\0.9 & 1 & 0.8\\\\0.1 & 0.8 & 1\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "To solve this, we'll need to use the determinant test:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&det(1) = 1 \\\\\n",
    "&det \\left( \\begin{bmatrix}1&0.9\\\\0.9&1\\end{bmatrix} \\right) = 0.19 \\\\\n",
    "&det(ABC) = (1)\\begin{bmatrix}1&0.8\\\\0.8&1\\end{bmatrix} - (0.9) \\begin{bmatrix}0.9&0.8\\\\0.1&1\\end{bmatrix} + (0.1) \\begin{bmatrix}0.9&0.1\\\\0.1&0.8\\end{bmatrix} = -0.307\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "$det(ABC)$ is not positive, which means $ABC$ is not a positive semidefinite matrix. Therefore, $ABC$ cannot be a covariance matrix if the correlation coefficient between $A$ and $C$ is 0.1.\n",
    "\n",
    "### Random Variable Functions\n",
    "\n",
    "Random Variable                             | Discrete Function           | Continuous Function\n",
    "--------------------------------------------|-----------------------------|---------------------------\n",
    "Cumulative Distribution Function (CDF)      | $F(a)$ = $P(x\\leq$ $a)$     | $F(a)$ = $\\int_{-\\infty}^{a} f(x)$$dx$\n",
    "Probability Mass/Density Function (PMF/PDF) | $P(X)$ = $P(X$$=x)$         | $f(x)$=$\\frac{d}{dx}F(x)$\n",
    "$E[x]$                                      | $\\sum_{P(x)>0}$$xP(x)$      | $\\int_{-\\infty}^{\\infty} xf(x)$$dx$\n",
    "$E[g(x)]$                                   | $\\sum_{P(x)>0}$$g(x)$$p(x)$ | $\\int_{-\\infty}^{\\infty} g(x)$$f(x)$$dx$\n",
    "$var(x)$                                    | $E[X^2]$ - $E[X]^2$\n",
    "$std(x)$                                    | $\\sqrt{varx}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
