{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Processes\n",
    "\n",
    "A stochastic process is the change of a random variable over time. Stochastic calculus is the counterpart of this process in continuous space. \n",
    "\n",
    "## Markov Process\n",
    "\n",
    "Only the present value is used to predict future values. This process is best represented using Markov chains. \n",
    "\n",
    "### Example\n",
    "\n",
    "*The Gambler's ruin problem: Player 1 starts off with $\\$1$ and Player 2 starts off with $\\$2$. The winner of each game wins $\\$1$. Player 1 is the favorite and wins $\\frac{2}{3}$ of the time. They continue playing until one player loses all of their money. What's the probability of Player 1 winning?*\n",
    "\n",
    "The probability of winning at each stage is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "p_0 &= 0, p_3 = 1 \\\\\n",
    "p_1 &= \\frac{1}{3}p_0 + \\frac{2}{3}p_2 = \\frac{2}{3}p_2 \\\\\n",
    "p_2 &= \\frac{1}{3}p_1 + \\frac{2}{3}p_3 = \\frac{1}{3}p_1 + \\frac{2}{3}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Solving this system of equations gives $p_1 = \\frac{4}{7}$ and $p_2 = \\frac{6}{7}$. Player 1 starts at $\\$ 1$, so the probability that they win is $\\frac{4}{7}$.\n",
    "\n",
    "## Martingale Process\n",
    "\n",
    "At any time $t$, the expected final value is the current value. A martingale stopped at a stopping time is a martingale. All Martingale's are Markovian, but not the other way around. \n",
    "\n",
    "## Random Walk\n",
    "\n",
    "A process $S_n$ is a random walk if $S_n = X_1 + \\cdots + X_n$ and each random variable {$X_i ; 1 \\leq i \\leq n $} is identical and independently distributed. Think of $S_n$ as your position at time $n$ after making $X_1, \\cdots, X_n$ successive random steps.\n",
    "\n",
    "### Symmetric Random Walk\n",
    "\n",
    "If you can only move backward or forward (i.e. $X_i = -1$ or $X_i = 1$) with probabilities $p$ and $1-p$, respectively, then $S_n$ is a simple random walk. In addition, if $p = \\frac{1}{2}$, then $S_n$ is considered to be a symmetric random walk. \n",
    "\n",
    "\\begin{equation*}\n",
    "S_{n+1} = \n",
    "\\begin{cases}\n",
    "      S_n + 1, &\\text{with probability}\\ p=\\frac{1}{2} \\\\\n",
    "      S_n - 1, &\\text{with probability}\\ p=\\frac{1}{2}\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "A symmetric random walk is a martingale. Here's a short proof of that:\n",
    "\n",
    "\\begin{equation*}\n",
    "E[S_{n+1} | S_n = s_n, \\cdots, S_1 = s_1] = \\frac{(S_n + 1) + (S_n - 1)}{2} = s_n\n",
    "\\end{equation*}\n",
    "\n",
    "We can also prove $S_n^2 - n$ is also a martingale:\n",
    "\n",
    "\\begin{equation*}\n",
    "E[S_{n+1}^2 - (n+1)] = \\frac{1}{2}[(S_n + 1)^2 + (S_n - 1)^2] - (n+1) = S_n^2 - n\n",
    "\\end{equation*}\n",
    "\n",
    "### Example\n",
    "\n",
    "*The drunken man problem: A drunk man is on a 100-ft long bridge. He's currently 23-ft in and has an equal probability of stumbling forwards or backwards. What's the probability that the drunk man makes it to the other end of the bridge (the 100-ft point)? The end where he started (the 0-ft point)? How many steps is he expected to take to reach either end?*\n",
    "\n",
    "The drunk man starts at 23-ft with $p = \\frac{1}{2}$. We can make this a symmetric random walk by setting his starting position to 0 and assuming he'll end up at either $\\alpha = -23$ (where he started) or $\\beta = 77$ (the end of the bridge). For a symmetric random walk, we know that $S_N$ and $S_N^2 - N$ are martingales, where $N$ is the total number of steps. That means his expected position at any time in the future is equal to his current position, which starts at zero. Therefore, \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "E[S_N] &= \\alpha p_{\\alpha} + \\beta p_{\\beta} = 77 p_{\\alpha} + (-27)(1 - p_{\\alpha}) = 0 \\\\\n",
    "\\Rightarrow p_{\\alpha} &= 0.26 \\\\\n",
    "\\Rightarrow p_{\\beta} &= 0.74\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "and \n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "E[S_N^2 - N] &= E[S_N^2] - E[N] = 77^2 p_{\\alpha} + (-27)^2(1 - p_{\\alpha}) - E[N]= 0 \\\\\n",
    "\\Rightarrow E[N] &= 2081\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "where $E[N]$ is the expected number of steps to reach either the 0-ft or 100-ft end of the bridge. Note, this is also equal to $\\alpha \\beta$.\n",
    "\n",
    "## Brownian Motion\n",
    "\n",
    "A continuous stochastic process $B(t)$ ~ $N(0, t)$ is a Brownian motion, also known as a Wiener process $W(t)$, if \n",
    "\n",
    "* $B(0) = 0$, meaning the process starts at 0.\n",
    "* Continuous everywhere, but differentiable nowhere.\n",
    "* $B(t) - B(s)$ ~ $N(0, t-s)$, meaning its increments are independent and normally distributed.\n",
    "\n",
    "A Brownian motion is a martingale. This is the martingale property:\n",
    "\n",
    "$E[W(t+s) | W(t)] = W(t)$ where $0 < s < t$.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let $B_t$ be a Brownian motion. What's the probability of $B_1 > 0$ and $B_2 < 0$? What if we know that $B_1 > 0$, what's the probability of $B_2 < 0$?\n",
    "\n",
    "If $B_t$ is a Brownian motion, then $B_1$ and $B_2 - B_1$ both follow $N(0, 1)$, which means they both have a half chance of being negative or positive. If $B_1 > 0$, then for $B_2 < 0$ we must have $B_2 - B_1 < -B_1$. Therefore,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "P(B_1 > 0, B_2 < 0) &= P(B_1 > 0, B_2 - B_1 < -B_1) \\\\\n",
    "&= P(B_1 > 0, B_2 - B_1 < 0, |B_2 - B_1| > |B_1|) \\\\\n",
    "&= p^3 = \\frac{1}{8}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "P(B_2 < 0) &= P(B_2 - B_1 < -B_1) \\\\\n",
    "&= P(B_2 - B_1 < 0, |B_2 - B_1| > |B_1|) \\\\\n",
    "&= p^2 = \\frac{1}{4}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "## Ito's Lemma\n",
    "\n",
    "Ito's Lemma is the stochastic counterpart of the chain rule. It's used to find the derivative (a stochastic differential equation, or SDE) of a time-dependent function of a stochastic process. Let $X_t$ be an Ito process where\n",
    "\n",
    "\\begin{equation*}\n",
    "dX_t = \\mu dt + \\sigma dW_t\n",
    "\\end{equation*}\n",
    "\n",
    "If $f(X_t, t)$ is a twice-differentiable function of $X(t)$ and $t$, then\n",
    "\n",
    "\\begin{equation*}\n",
    "df = \\frac{\\delta f}{\\delta t}dt + \\frac{\\delta f}{\\delta x}dX_t + \\frac{1}{2} \\frac{\\delta^2 f}{\\delta x^2}(dX_t)^2\n",
    "\\end{equation*}\n",
    "\n",
    "Using the definition of $dX_t$ above and the fact that $dX_t^2 = \\mu^2 dt^2 + 2 \\mu \\sigma dt dW_t + \\sigma^2 dW_t^2 = \\sigma^2 dt$, we can rewrite Ito's formula as\n",
    "\n",
    "\\begin{equation*}\n",
    "df = \\left( \\frac{\\delta f}{\\delta t} + \\mu \\frac{\\delta f}{\\delta x} + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} \\right)dt + \\sigma \\frac{\\delta f}{\\delta x} dW_t\n",
    "\\end{equation*}\n",
    "\n",
    "Where $\\frac{\\delta f}{\\delta t} + \\mu \\frac{\\delta f}{\\delta x} + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2}$ is the drift rate (the rate at which the expected value of a process changes) and $\\sigma \\frac{\\delta f}{\\delta x} dW_t$ is the stochastic component. Random variable $X$ has a drift rate of $\\mu$ and a variance of $\\sigma^2$. For Brownian motion, $\\mu = 0$ (because $B_t$ is a martingale) and $\\sigma = 1$. \n",
    "\n",
    "### Properties\n",
    "\n",
    "The following properties stem from the fact that the variance of $B_t$ is equal to $t$\n",
    "\n",
    "* $dt^2 = 0$; the quadratic variation of the identity function with itself is 0.\n",
    "* $dt dB_t = 0$; the cross variation of Brownian motion with the identity function is 0. \n",
    "* $dB_t^2 = dt$; the quadratic variation of Brownian motion with itself over time $t$ is equal to $dt$.\n",
    "\n",
    "#### Proof\n",
    "\n",
    "Starting with the proof of $dt^2 = 0$ and knowing that $dt = (t + dt) - t$ and $E[dt] = 0$, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "dt^2 = E[(t + dt - t)^2] = E[dt^2] = 0\n",
    "\\end{equation*}\n",
    "\n",
    "Second, for the proof of $dtdB_t = 0$, knowing that $E[B_t] = 0$ gives us:\n",
    "\n",
    "\\begin{equation*}\n",
    "dt dB_t = E[(t + dt - t)(B_{t + dt} - B_t)] = E[dt(B_{t + dt} - B_t)] = 0\n",
    "\\end{equation*}\n",
    "\n",
    "And lastly, the proof for $dB_t^2 = dt$. The change in $B_t$ from time $t$ to $t + dt$ is equal to the average (or expectation) of that interval. Knowing that $\\text{var}(B_t) = E[B_t^2] - E[B_t]^2 = E[B_t^2]$, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "dB_t^2 = E[(B_{t + dt} - B_t)^2] = \\text{var}(B_{t+dt} - B_t) = t + dt - t = dt\n",
    "\\end{equation*}\n",
    "\n",
    "### Examples\n",
    "\n",
    "1. If $B_t$ is a Brownian motion and $Z_t = \\sqrt{t}B_t$, what's the mean and variance of $Z_t$? Is it a martingale? \n",
    "\n",
    "    We know that $B_t$ ~ $N(0, t)$ and is symmetric about 0. $\\sqrt{t}$ is a constant at time $t$, so $Z_t = \\sqrt{t}B_t$ must also be symmetric about 0 with a mean of 0 and variance of $t(var(B_t)) = t^2$. Second, in order for $Z_t$ to a be a martingale, it must have a drift rate of zero. We can check for this by applying Ito's lemma to $Z_t$:\n",
    "\n",
    "    \\begin{equation*}\n",
    "    \\begin{split}\n",
    "    dZ_t &= \\left( \\frac{\\delta Z_t}{\\delta t} + \\beta\\frac{\\delta Z_t}{\\delta B_t} + \\frac{1}{2} \\gamma^2 \\frac{\\delta^2 Z_t}{\\delta B_t^2} \\right)dt + \\gamma \\frac{\\delta Z_t}{\\delta B_t} dB_t \\\\\n",
    "    &= \\frac{1}{2}t^{-\\frac{1}{2}} B_t dt + \\sqrt{t}dB_t\n",
    "    \\end{split}\n",
    "    \\end{equation*}\n",
    "\n",
    "    Since $B_t \\neq 0$, the drift term  $\\frac{1}{2}t^{-\\frac{1}{2}} B_t dt \\neq 0$. Therefore, $Z_t$ isn't a martingale.\n",
    "\n",
    "\n",
    "2. Given $dS_t = \\mu S_t dt + \\sigma S_t dW_t$, what's an SDE for $log(S_t)$?\n",
    "\n",
    "    Let $X_t = log(S_t)$. Applying this to Ito's lemma and using its properties listed above, we have:\n",
    "    \n",
    "    \\begin{equation*}\n",
    "    \\begin{split}\n",
    "    dX_t &= \\frac{\\delta X_t}{\\delta t} dt + \\frac{\\delta X_t}{\\delta S_t} dS_t + \\frac{1}{2} \\frac{\\delta^2 X_t}{\\delta X_t^2} dS_t^2 \\\\\n",
    "    &= \\frac{1}{S_t}(\\mu S_t dt + \\sigma S_t dW_t) - \\frac{1}{2S_t^2} (\\mu^2 S_t^2 dt^2 + 2\\mu \\sigma S_t^2 dt dW_t + \\sigma^2 S_t^2 dW_t^2) \\\\\n",
    "    &= \\left(\\mu - \\frac{1}{2}\\sigma^2 \\right) dt + \\sigma dW_t\n",
    "    \\end{split}\n",
    "    \\end{equation*}  \n",
    "    \n",
    "    To find the closed-form solution of $X_t$, let's integrate both sides of $dX_t$ above:\n",
    "    \n",
    "    \\begin{equation*}\n",
    "    \\begin{split}\n",
    "    \\int_{0}^t dX_t &= \\int_{0}^t log(S_t) =  \\int_{0}^t (\\mu - \\frac{1}{2}\\sigma^2)dt + \\int_{0}^{t} \\sigma dW_t \\\\\n",
    "    \\Rightarrow log \\left( \\frac{S_t}{S_0} \\right) &= (\\mu - \\frac{1}{2}\\sigma^2)t + \\sigma (W_t - W_0) \\\\\n",
    "    \\Rightarrow S_t &= S_0 e^{(\\mu - \\frac{1}{2}\\sigma^2)t + \\sigma (W_t - W_0)} \n",
    "    \\end{split}\n",
    "    \\end{equation*} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Feynman-Kac Theorem\n",
    "\n",
    "The Feynman-Kac theorem states that the only solution to a PDE with a boundary condition of $f(x, T) = g(x)$ and of the form:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\delta f}{\\delta t} + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} = 0\n",
    "\\end{equation*}\n",
    "\n",
    "is a conditional expectation:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(X, t) = E[g(X_T) | X_t = x, dX_t = \\sigma dW_t]\n",
    "\\end{equation*}\n",
    "\n",
    "### Proof\n",
    "\n",
    "To show this holds, let's begin by applying Ito's lemma to $f$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "df(X_t, t) &= \\left( \\frac{\\delta f}{\\delta t} (X_t, t) + \\mu \\frac{\\delta f}{\\delta x} (X_t, t) + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} (X_t, t) \\right) dt + \\sigma \\frac{\\delta f}{\\delta x}(X_t, t)dW_t \\\\\n",
    "&= \\left( \\frac{\\delta f}{\\delta t} (X_t, t) + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} (X_t, t) \\right) dt + \\sigma \\frac{\\delta f}{\\delta x}(X_t, t)dW_t\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "since $\\mu = 0$. And hence:\n",
    "\n",
    "\\begin{equation*}\n",
    "E[df(X_t, t) | X_t] = \\left( \\frac{\\delta f}{\\delta t} (X_t, t) + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} (X_t, t) \\right) dt\n",
    "\\end{equation*}\n",
    "\n",
    "Also, by definition of $f$, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "E[df(X_t, t) | X_t] &= E[f(X_{t+dt}, t + dt)| X_t] - f(X_t, t) \\\\\n",
    "&= E[E[g(X_T)|X_{t+dt}]|X_t] - E[g(X_T)|X_t] \\\\\n",
    "&= E[g(X_T) | X_t] - E[g(X_T) | X_t] = 0\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Equating the two definitions of $E[df(X_t, t) | X_t]$ gives us the following:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\left( \\frac{\\delta f}{\\delta t} (X_t, t) + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} (X_t, t) \\right) dt = 0 \\\\\n",
    "\\Rightarrow \\frac{\\delta f}{\\delta t} (X_t, t) + \\frac{1}{2} \\sigma^2 \\frac{\\delta^2 f}{\\delta x^2} (X_t, t) = 0\n",
    "\\end{split}\n",
    "\\end{equation*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
