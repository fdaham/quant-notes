{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Variable Functions\n",
    "\n",
    "Random Variable                             | Discrete Function           | Continuous Function\n",
    "--------------------------------------------|-----------------------------|---------------------------\n",
    "Cumulative Distribution Function (CDF)      | $F(a)$ = $P(x\\leq$ $a)$     | $F(a)$ = $\\int_{-\\infty}^{a} f(x)$$dx$\n",
    "Probability Mass/Density Function (PMF/PDF) | $P(X)$ = $P(X$$=x)$         | $f(x)$=$\\frac{d}{dx}F(x)$\n",
    "$E[x]$                                      | $\\sum_{P(x)>0}$$xP(x)$      | $\\int_{-\\infty}^{\\infty} xf(x)$$dx$\n",
    "$E[g(x)]$                                   | $\\sum_{P(x)>0}$$g(x)$$P(x)$ | $\\int_{-\\infty}^{\\infty} g(x)$$f(x)$$dx$\n",
    "$var(x)$                                    | $E[X^2]$ - $E[X]^2$\n",
    "$std(x)$                                    | $\\sqrt{varx}$\n",
    "\n",
    "## Expected Value\n",
    "\n",
    "The expected value of a random variable, $E[X]$, is the weighted average of its possible outcomes. If random variable $X$ is **discrete** with probability $P(X = x)$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "E [X] = \\sum x P(x)\n",
    "\\label{eq:1} \\tag{1}\n",
    "\\end{equation*}\n",
    "\n",
    "If $X$ is **continuous** with a PDF of $f(x)$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "E [X] = \\int_{-\\infty}^{\\infty} xf(x)dx\n",
    "\\label{eq:2} \\tag{2}\n",
    "\\end{equation*}\n",
    "\n",
    "### Linearity of expectation\n",
    "\n",
    "Linearity of expectation states that the sum of the expected values of random variables is the sum of their individual expected values--regardless of whether they are independent or not. For random variables $X$ and $Y$, this means:\n",
    "\n",
    "\\begin{equation*}\n",
    "E [X+Y] = E[X] + E[Y]\n",
    "\\label{eq:3} \\tag{3}\n",
    "\\end{equation*}\n",
    "\n",
    "More generally,\n",
    "\n",
    "\\begin{equation*}\n",
    "E \\left[ \\sum_{i=1}^{n} X_i \\right] = \\sum_{i=1}^{n} E[X_i]\n",
    "\\label{eq:4} \\tag{4}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Example\n",
    "\n",
    "*You throw a fair coin one million times. What is the expected number of occurences of HHHHHHTTTTTT?*\n",
    "\n",
    "The probability $p_i$ of getting HHHHHHTTTTTT is $\\frac{1}{2^{12}}$. For one million tosses, there are $n = 1000000 - 11$ possible chances for this sequence to occur. Let $X_i$ have a value of $1$ if the sequence starting at $i$ is equal to HHHHHHTTTTTT. Then, using the linearity of expectation, we have:\n",
    "\n",
    "\\begin{equation*}\n",
    "E \\left[ \\sum_{i=1}^{n} X_i \\right] = \\sum_{i=1}^{n} E[X_i] = n p_i = \\frac{1000000-11}{2^{12}}\n",
    "\\end{equation*}\n",
    "\n",
    "### Law of Total Expectation\n",
    "\n",
    "The law of total expectation, also known as the tower rule, states that if some random variable $X$ has an expected value of $E[X]$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "E[X] = E \\left[ E[X] | Y \\right]\n",
    "\\label{eq:5} \\tag{5}\n",
    "\\end{equation*}\n",
    "\n",
    "where $Y$ is another random variable that exists in the same probability space as $X$. In other words:\n",
    "\n",
    "\\begin{equation*}\n",
    "E[X] = \\sum_y E[X|Y = y] P(y)\n",
    "\\label{eq:6} \\tag{6}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Example\n",
    "\n",
    "*What is the expected number of coin tosses needed to get $n$ consecutive heads?*\n",
    "\n",
    "We're going to solve this using a recursive function. Let $X_n$ be the number of coin tosses needed to get $n$ heads in a row. On the half chance that we get heads on the $n$th flip, the expected number of flips needed to get $n$ heads in a row is the number of flips needed to get the previous $n-1$ consecutive heads plus the current flip. Similarly, if we get tails, we've done the same number of flips, but now we have to start over again. So,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "E[X_n] &= E[X_n | H] P(H) + E[X_n | T] P(T) \\\\\n",
    "&= \\frac{1}{2}(E[X_{n-1}] + 1) + \\frac{1}{2}(E[X_{n-1}] + 1 + E[X_k]) \\\\\n",
    "&= 2E[X_{n-1}] + 2\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "We can evaluate this for the first few cases of $E[X_n]$, which I'll denote as $E_n$ from here on out:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "E_1 &= 2 \\\\\n",
    "E_2 &= 2E_1 + 2 = 2^2 + 2 \\\\\n",
    "E_3 &= 2E_2 + 2 = 2(2^2 + 2) + 2  = 2^3 + 2^2 + 2\\\\\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "We see a pattern emerging. Inductively, we have $E_1 = 2$. If $E_{n-1} = 2^{n-1} + \\cdots + 2$, then:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "E_n &= 2E_{n-1} + 2 \\\\\n",
    "&= 2(2^{n-1} + \\cdots + 2) + 2 \\\\\n",
    "&= 2^n + \\cdots + 2^2 + 2\n",
    "\\end{split}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance, Covariance, and Correlation\n",
    "\n",
    "The variance of a random variable $X$ can be written in the terms of the standard deviation of $X$, $\\sigma_X$, and the expected value of X:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\text{var}(X) &= \\sigma_X^2 \\\\\n",
    "&= E[(X - E[X])^2] \\\\\n",
    "&= E[X^2] - E[X]^2\n",
    "\\end{split}\n",
    "\\label{eq:7} \\tag{7}\n",
    "\\end{equation*}\n",
    "\n",
    "The covariance of random variables $X$ and $Y$, each with $n$ values (i.e. $x_1, x_2, \\cdots, x_n$ and $y_1, y_2, \\cdots, y_n$), is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\text{Cov}(X, Y) &= E[XY] - E[X]E[Y] \\\\\n",
    "&= \\frac{1}{n} \\sum_{i=1}^{n} (x_i-\\bar{x})(y_i-\\bar{y})\n",
    "\\end{split}\n",
    "\\label{eq:8} \\tag{8}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\bar{x}$ and $\\bar{y}$ are the means of $X$ and $Y$, respectively. \n",
    "\n",
    "And the Pearson correlation coefficient of $X$ and $Y$ is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\rho(X, Y) &= \\frac{\\text{Cov}(X, Y)}{\\text{var}(X)\\text{var}(Y)} \\\\\n",
    "&= \\beta \\frac{\\sigma_x}{\\sigma_y}\n",
    "\\end{split}\n",
    "\\label{eq:9} \\tag{9}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\beta$ is the slope of $Y = \\alpha + \\beta X$. If $X$ and $Y$ are independent, then $\\text{Cov}(X, Y) = 0$ and $\\rho(X, Y) = 0$. \n",
    "\n",
    "### Example\n",
    "\n",
    "*(From [HackerRank](https://www.hackerrank.com/challenges/s10-mcq-7/problem)) The regression line of $y$ on $x$ is $3x + 4y + 8 = 0$ and $4x + 3y + 7 = 0$ for $x$ on $y$. Find $\\rho$.*\n",
    "\n",
    "From the two regression lines, we get:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "3x + 4y + 8 = 0 &\\Rightarrow y = -2 - \\frac{3}{4}x \\\\\n",
    "4x + 3y + 7 = 0 &\\Rightarrow x = -\\frac{7}{4} - \\frac{3}{4}y\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Multiplying $\\rho$ of both regression lines gives us:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\rho^2 &= \\left( -\\frac{3}{4} \\frac{\\sigma_x}{\\sigma_y} \\right) \\left( -\\frac{3}{4} \\frac{\\sigma_y}{\\sigma_x} \\right) \\\\\n",
    "&= \\frac{9}{16}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Since the slopes of the two regression lines are both negative, we know that $x$ and $y$ are negatively correlated. Therefore, $\\rho = -\\frac{3}{4}$.\n",
    "\n",
    "### Covariance Matrices\n",
    "\n",
    "Covariance matrices show the covariance between variables. They are symmetrical and positive semidefinite--meaning all values in the matrix are greater than or equal to zero. The determinant test is used to determine whether a matrix is a covariance matrix by computing the determinants of the growing submatrices in the upper left corner of the matrix. If they are all positive semidefinite, then the matrix is a covariance matrix.\n",
    "\n",
    "#### Example\n",
    "\n",
    "*For three assets $A$, $B$, and $C$, the correlation coefficient of $A$ and $B$ is 0.9 and is 0.8 for $B$ and $C$. Can $A$ and $C$ have a correlation coefficient of 0.1?*\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{ABC} = \\begin{bmatrix}V_{A,A}&C_{A,B}&C_{A,C}\\\\C_{B,A}&V_{B,B}&C_{B,C}\\\\C_{C,A}&C_{C,B}&V_{C,C}\\end{bmatrix} = \\begin{bmatrix}1 & 0.9 & 0.1\\\\0.9 & 1 & 0.8\\\\0.1 & 0.8 & 1\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "To solve this, we'll need to use the determinant test:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "&\\text{det}(1) = 1 \\\\\n",
    "&\\text{det} \\left( \\begin{bmatrix}1&0.9\\\\0.9&1\\end{bmatrix} \\right) = 0.19 \\\\\n",
    "&\\text{det}(\\text{ABC}) = (1)\\begin{bmatrix}1&0.8\\\\0.8&1\\end{bmatrix} - (0.9) \\begin{bmatrix}0.9&0.8\\\\0.1&1\\end{bmatrix} + (0.1) \\begin{bmatrix}0.9&0.1\\\\0.1&0.8\\end{bmatrix} = -0.307\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "$\\text{det}(\\text{ABC})$ is not positive, which means $\\text{ABC}$ is not a positive semidefinite matrix. Therefore, $\\text{ABC}$ cannot be a covariance matrix if the correlation coefficient between $A$ and $C$ is 0.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
